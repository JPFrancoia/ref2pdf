#!/usr/bin/python
# coding: utf-8

help = """reftool.py

Very simple script to return a DOI from a formatted citation.
Can also return a direct link to download the article from Sci-Hub.

This script uses Crossref Simple Text Query Tool:
http://www.crossref.org/SimpleTextQuery/

Usage is limited to 1000 requests per user/per month, and requires signing up
on Crossref's website. The script needs the email address you used to sign up.

Examples:
    Input: ./reftool.py myemail@mydomain.com "J.-P. Francoia, R. Pascal and L. Vial, Chem. Commun., 2015, 51, 1953"
    Output: DOI: http://dx.doi.org/10.1039/C4CC08563A

    Input: ./reftool.py -d myemail@mydomain.com "J.-P. Francoia, R. Pascal and L. Vial, Chem. Commun., 2015, 51, 1953"
    Output: Link to download the article: http://cyber.sci-hub.cc/MTAuMTAzOS9jNGNjMDg1NjNh/francoia2014.pdf

    Input: ./reftool.py -bd http://dx.doi.org/10.1039/C4CC08563A
    Output:
            @article{Francoia_2015,
            doi = {10.1039/c4cc08563a},
                url = {http://dx.doi.org/10.1039/C4CC08563A},
                year = 2015,
                publisher = {Royal Society of Chemistry ({RSC})},
                volume = {51},
                number = {10}number,
                pages = {1953--1956},
                author = {Jean-Patrick Francoia and Robert Pascalscal and Laurent Vial},
                title = {Monitoring clinical levels of heparin in human blood samples with an indicator-displacement assay},
                journal = {Chem. Commun.}
            }

            Link to download the article: http://cyber.sci-hub.cc/MTAuMTAzOS9jNGNjMDg1NjNh/francoia2014.pdf

Usage:
    reftool.py   [options] ([email] <ref_or_doi> | <email> <ref_or_doi>)

Options:
    -h --help    Display help
    -a           Option All, Equivalent to -bd
    -b           Output a bibtex entry (get information about the reference)
    -d           Output a link to download the artice from Sci-Hub (could be illegal, use at your own risk)
"""


import sys
import requests
from bs4 import BeautifulSoup, SoupStrainer
from docopt import docopt
import validators


# Define URLs
URL_CROSSREF = "http://www.crossref.org/SimpleTextQuery/"
URL_SCIHUB = "http://sci-hub.cc/"
URL_DOI_BIB = "http://dx.doi.org/"

# Define the user agent
headers = {'User-agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0'}

# Get the arguments
args = docopt(help)
email = args['<email>']
target = args['<ref_or_doi>']

# If option 'all' activated, switch the other options
if args['-a']:
    args['-b'] = True
    args['-d'] = True


# Test if the input is a doi
if target.startswith('10.'):
    is_doi = True
    doi = target
elif validators.url(target) and '10.1' in target:
    doi = target.split(URL_DOI_BIB)[-1]
    is_doi = True
else:
    is_doi = False


# if ref_or_doi is a ref, find its DOI
if not is_doi:

    # First, get the form and start a session. This is necessary, posting directly
    # the parameters doesn't work
    s = requests.session()
    s.get(URL_CROSSREF)

    payload = {'email': email,
               'command': 'Submit',
               'freetext': target}

    # Post the form
    req = s.post(URL_CROSSREF, data=payload, headers=headers)

    with open('out.html', 'w') as output:
        output.write(req.text)

    # Parse the result
    strainer = SoupStrainer("td", attrs={"class": "resultB"})
    soup = BeautifulSoup(req.text, "lxml", parse_only=strainer)
    r = soup("td", attrs={"class": "resultB"})

    try:
        doi = soup.a.text
        doi = doi.split("http://dx.doi.org/")[-1]
        print('DOI: {}\n'.format(doi))
    except Exception as e:
        print("reftool could not get the DOI from your reference.")
        print("A possible reason is an unregistered email address.")
        sys.exit()


# if option bibtex activated, request the bibtex entry
if args['-b']:
    headers = {"Accept": "application/x-bibtex"}
    r = requests.get(URL_DOI_BIB + doi, headers=headers)

    if "Error: DOI Not Found" in r.text:
        print("DOI not found. Are you sure you didn't make a typo ?")
        print("Impossible to generate a bibtex entry\n")
    else:
        print(r.text + "\n")

    headers['Accept'] = ""


# If option download is activated, request the paper from Sci-Hub
if args['-d']:

    # Post the form
    payload = {'sci-hub-plugin-check': '', 'request': doi}
    req = requests.post(URL_SCIHUB, data=payload, headers=headers)

    # Past the result to get the link of the paper
    strainer = SoupStrainer("iframe", attrs={"id": "pdf"})
    soup = BeautifulSoup(req.text, "lxml", parse_only=strainer)

    link_to_pdf = soup.iframe['src']

    if not link_to_pdf.startswith('http:'):
        link_to_pdf = 'http:' + link_to_pdf

    print('Link to download the article: {}'.format(link_to_pdf))


if __name__ == '__main__':
    pass
